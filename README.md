# ä¸‹å­¦æœŸç¬¬ä¸€æ¬¡ä»»åŠ¡

##### å¤ç°éœ€è¦å°†deviceæ”¹ä¸ºcudaï¼Œæœ¬æœºä½¿ç”¨mps

## ä¸€.  MINISTæ‰‹å†™æ•°æ®é›†è¯†åˆ«

### ä½¿ç”¨æœ€å¼±çš„å…¨è¿æ¥ç½‘ç»œè¿›è¡Œè®­ç»ƒ

ä½¿ç”¨pytorchè‡ªå¸¦çš„ministæ•°æ®é›†APIè¿›è¡Œå¯¹äºæ•°æ®é›†çš„ä¸‹è½½

~~å¼€è¢‹å³é£Ÿ~~

```python
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)
```

å¯¹äºå…¨å±€å˜é‡çš„å®šä¹‰

```python
# 2. å®šä¹‰è¶…å‚æ•°
input_size = 784  # MNISTå›¾ç‰‡å¤§å°æ˜¯28x28
hidden_sizes = [128, 64]  # éšè—å±‚çš„å¤§å°
output_size = 10  # è¾“å‡ºçš„ç±»åˆ«æ•°ä¸º10ï¼Œåˆ†åˆ«å¯¹åº”0åˆ°9çš„æ•°å­—
num_epochs = 50  # è¿›è¡Œ5æ¬¡è®­ç»ƒè¿­ä»£
batch_size = 64  # æ¯æ‰¹æ¬¡å¤„ç†64å¼ å›¾ç‰‡
learning_rate = 0.001  # å­¦ä¹ ç‡è®¾ç½®ä¸º0.001

# 3. æ•°æ®å‡†å¤‡
transform = transforms.Compose([
    transforms.ToTensor(),  # å°†å›¾ç‰‡è½¬æ¢æˆPyTorchçš„Tensoræ ¼å¼
    transforms.Normalize((0.5,), (0.5,))  # æ ‡å‡†åŒ–å¤„ç†ï¼Œä»¥å‡å°æ¨¡å‹å¯¹æ•°æ®è§„æ¨¡çš„æ•æ„Ÿæ€§
])
```
å¯¹äºç¥ç»ç½‘ç»œå®šä¹‰çš„éƒ¨åˆ†ï¼Œç›´æ¥æš´åŠ›å…¨è¿æ¥ä¸‰å±‚

```python
 def __init__(self, input_size, hidden_sizes, output_size):
        super(NeuralNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_sizes[0])
        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])
        self.fc3 = nn.Linear(hidden_sizes[1], output_size)
        self.relu = nn.ReLU()
```
ä¼ æ’­å‡½æ•°ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°è¿›è¡Œæ¿€æ´»

```python
def forward(self, x):
    x = self.relu(self.fc1(x))
    x = self.relu(self.fc2(x))
    x = self.fc3(x)
    return x
```

è®­ç»ƒçš„æ•ˆæœä¼¼ä¹æ˜¯ä¸å·®çš„ï¼Œä½†æ˜¯é—®é¢˜å‡ºåœ¨äº†OJä¸Šè¯„æµ‹çš„æ—¶å€™ä¼¼ä¹model_load_error

æ¨¡å‹ä¿å­˜çš„é—®é¢˜ï¼Ÿä½†æ˜¯æ¥ä¸‹æ¥ä½¿ç”¨çš„cnnç½‘ç»œæ²¡æœ‰é—®é¢˜

### ä½¿ç”¨CNNç¥ç»ç½‘ç»œè¿›è¡Œå›¾åƒçš„åˆ†æ

```python
def __init__(self):
        super(Net, self).__init__()
        # å·ç§¯å±‚
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.batchnorm1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.batchnorm2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.batchnorm3 = nn.BatchNorm2d(128)
        # Dropoutå±‚
        self.dropout1 = nn.Dropout2d(0.25)
        self.dropout2 = nn.Dropout2d(0.5)
        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(128 * 7 * 7, 256) # æ›´æ­£å…¨è¿æ¥å±‚è¾“å…¥ç‰¹å¾æ•°
        self.fc2 = nn.Linear(256, 10)

    def forward(self, x):
        x = F.relu(self.batchnorm1(self.conv1(x)))
        x = F.relu(self.batchnorm2(self.conv2(x)))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.batchnorm3(self.conv3(x)))
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = self.dropout2(x)
        x = self.fc2(x)
        output = F.log_softmax(x, dim=1)
        return output
```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªå…·æœ‰å¤šä¸ªå·ç§¯å±‚ã€æ‰¹é‡å½’ä¸€åŒ–å±‚å’Œå…¨è¿æ¥å±‚çš„å·ç§¯ç¥ç»ç½‘ç»œ

`self.conv1` ç¬¬ä¸€ä¸ªå·ç§¯å±‚ï¼Œä½¿ç”¨ä¸€ä¸ªå•é€šé“çš„è¾“å…¥ï¼Œè¾“å‡º32ä¸ªç‰¹å¾æ˜ å°„ï¼Œå¹¶ä½¿ç”¨å¤§å°ä¸º3x3çš„å·ç§¯æ ¸å’Œ1çš„å¡«å……ï¼Œä»¥ç¡®ä¿åœ¨å·ç§¯æ“ä½œåè¾“å‡ºçš„ç»´åº¦ä¸å˜ã€‚

`self.batchnorm1` ç¬¬ä¸€ä¸ªæ‰¹é‡å½’ä¸€åŒ–å±‚ï¼Œå®ƒå¯¹åº”äºå·ç§¯å±‚conv1çš„è¾“å‡ºã€‚æ‰¹é‡å½’ä¸€åŒ–å¯ä»¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚

`self.dropout1`å’Œ`self.dropout2`æ˜¯Dropoutå±‚ï¼Œè¿™ä¸¤å±‚åˆ†åˆ«ä»¥0.25å’Œ0.50çš„æ¦‚ç‡æš‚æ—¶ä¸¢å¼ƒä¸€éƒ¨åˆ†ç‰¹å¾ï¼Œä»¥å‡å°‘æ¨¡å‹è¿‡æ‹Ÿåˆã€‚

æœ€åæ·»åŠ ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼Œçœ‹èµ·æ¥ä¼¼ä¹å¯ä»¥å¢åŠ å¯¹äºMINISTæ•°æ®é›†è¯†åˆ«çš„å‡†ç¡®åº¦

å¯¹ï¼Œ`çœ‹èµ·æ¥` `ä¼¼ä¹`

é‰´äºæˆ‘ç°åœ¨å¯¹äºå„ç§æœºå™¨å­¦ä¹ çš„ç»“æ„ä»…ä¿ç•™åœ¨æŠŠä¸åŒåŠŸèƒ½çš„â€œç§¯æœ¨â€æ­èµ·æ¥çš„é˜¶æ®µã€‚

æ‰€ä»¥è¿™ä¸ªç½‘ç»œçœ‹èµ·æ¥æŒºå¥½ï¼Œè¡¨ç°ä¹Ÿå°±ä¸€èˆ¬ã€‚

å¹¶ä¸”é—®é¢˜å‡ºåœ¨äº†è¿™ä¸ªç½‘ç»œä¼šéšç€è®­ç»ƒçš„epochå¢åŠ åˆ†æ•°é™ä½ã€‚ã€‚ã€‚

ğŸ˜­

## äºŒ.YOLOv8æ£€æµ‹

### ç¯å¢ƒé…ç½®

ä½¿ç”¨çš„macosç³»ç»Ÿï¼Œä¸éœ€è¦æcudaï¼Œç›´æ¥

`pip install ultralytics`

ä½†æ˜¯ç”±äºä¸æƒ³è®©è‡ªå·±çš„ç”µè„‘å¤ªéš¾å—ï¼Œæ‰€ä»¥ç™½å«–`Google`çš„å¡

![alt text](image.png)

### è®­ç»ƒ

é¦–å…ˆå¤„ç†ä¸€ä¸‹æ•°æ®é›†ï¼Œæä¾›çš„æ•°æ®é›†æ ¼å¼ä¼¼ä¹å¹¶ä¸èƒ½ç›´æ¥æ»¡è¶³ultralyticsé›†æˆçš„yoloçš„è®­ç»ƒï¼Œæ‰€ä»¥å…ˆåˆ†æä¸€ä¸‹æ•°æ®é›†çš„æ„æˆã€‚

å¯ä»¥å‘ç°è¿™ä¸ªæ•°æ®é›†å¹¶æ²¡æœ‰åˆ†å¼€train,valid,testçš„éƒ¨åˆ†ï¼Œæˆ‘é€šå¸¸æŒ‰ç…§7:2:1çš„æ¯”ä¾‹è¿›è¡Œåˆ†å‰²ï¼ˆroboflowçš„é»˜è®¤åˆ†å‰²æ–¹å¼ï¼‰

![alt text](image-1.png)

åœ¨æœ¬ç›®å½•ä¸‹è¿˜å­˜åœ¨æœ‰data.yamlç”¨äºé…ç½®æ•°æ®é›†

```yaml
names:
- '0'
nc: 1
test: ./test/images
train: ./train/images
val: ./valid/images
```
å¯¹äºæ•°æ®é›†çš„åˆ†é…ï¼Œå¯ä»¥å¾ˆå¿«ä½¿ç”¨shutilæ¨¡å—è¿›è¡Œå¤åˆ¶ã€‚

```python
import os,shutil

folder_path = './data_hero/images'

files_and_folders = os.listdir(folder_path)

file_names = [os.path.splitext(f)[0] for f in files_and_folders if os.path.isfile(os.path.join(folder_path, f))]

total_num = len(file_names)

train_num = int(0.7 * total_num)

valid_num = int(0.2 * total_num)

test_num = total_num - valid_num - train_num

image_dir = 'data_hero/images'
label_dir = 'data_hero/labels'

def cp(source_file,dst_folder):
    if not os.path.exists(dst_folder):
        os.makedirs(dst_folder)
    destination_file = os.path.join(dst_folder, os.path.basename(source_file))
    shutil.copy2(source_file,destination_file)

for index in range(train_num):
    cp(os.path.join(image_dir,file_names[index] + '.jpg'),'data_hero/train/images')
    cp(os.path.join(label_dir,file_names[index] + '.txt'),'data_hero/train/labels')


for index in range(train_num,train_num+valid_num):
    cp(os.path.join(image_dir,file_names[index] + '.jpg'),'data_hero/valid/images')
    cp(os.path.join(label_dir,file_names[index] + '.txt'),'data_hero/valid/labels')

for index in range(train_num+valid_num,total_num):
    cp(os.path.join(image_dir,file_names[index] + '.jpg'),'data_hero/test/images')
    cp(os.path.join(label_dir,file_names[index] + '.txt'),'data_hero/test/labels')
```

ç°åœ¨ä¼¼ä¹æ˜¯åªæ¬ ä¸œé£ï¼Ÿ

ç›´æ¥ç”¨`ultralytics`é›†æˆçš„å‘½ä»¤è¡Œå·¥å…·è¿›è¡Œè®­ç»ƒ

`yolo task=detect mode=train model=yolov8x.pt data=/Users/xin/Documents/Githubtemp/ML_studying/data_hero/data.yaml epochs=50 imgsz=640 device=mps`

ç”±äºåœ¨colabä¸Šè¿›è¡Œè®­ç»ƒï¼Œdeviceå†™cudaæˆ–è€…ä¸å†™éƒ½å¯

ç”±äºæ•°æ®é›†æ¯”è¾ƒåºå¤§å¹¶ä¸”åœ¨è®­ç»ƒçš„æ—¶å€™ä½¿ç”¨çš„æ˜¯xç±»å‹çš„æ¨¡å‹ï¼Œè®­ç»ƒçš„æ—¶é—´ä¼šæ¯”è¾ƒé•¿

~~å¯èƒ½æ˜¯å¡çš„é…ç½®å¤ªä½~~

![alt text](image-2.png)

å¹³å‡ä¸€ä¸ª`epoch`ä½¿ç”¨äº†`1min30s`ï¼Œå¹¶ä¸”æŠŠæ˜¾å­˜å¹²æ»¡äº†ã€‚ã€‚ã€‚

å½“ç„¶ä¹Ÿè®­ç»ƒå‡ºäº†æœ€å°çš„`nano`æ¨¡å‹ï¼Œæ„Ÿè§‰è¡¨ç°å¹¶æ²¡æœ‰ç‰¹åˆ«ä¼˜ç§€

æœ€ç»ˆä½¿ç”¨äº†`yolov8x.pt`è®­ç»ƒå‡ºçš„æ¨¡å‹ï¼Œä¸€å…±è®­ç»ƒ`70 epochs`é€‰å–å…¶ä¸­`best`æ¨¡å‹è¿›è¡Œæ¨ç†

æœ¬åœ°å®æµ‹mpsç¡¬ä»¶åŠ é€Ÿå¯ä»¥è¾¾åˆ°å¹³å‡ä¸åˆ°30msä¸€å¸§

![alt text](image-3.png)

å¼€å§‹çš„æ—¶å€™å‘ç°å³ä¸‹è§’çš„æœºå™¨äººä¼šæœ‰é‡å è¾¹æ¡†çš„ç°è±¡å‡ºç°ï¼Œè¿™æ˜¯ç”±äºæœ¬èº«é»˜è®¤çš„`iou`å€¼è¾ƒå¤§å¯¼è‡´ä½¿å¾—ä¸€ä¸ªæœºå™¨äººè¢«å¤šæ¬¡è¯†åˆ«ï¼Œé€‚å½“è°ƒå°`iou`å€¼å³å¯
![alt text](image-4.png)

æœ€ç»ˆè°ƒèŠ‚å‡ºçš„é¢„æµ‹æ¨¡å¼ï¼š

`yolo task=detect mode=predict  model=detect_x_70.pt source='./test.mp4' device=mps show=True iou=0.4 conf=0.15`

ä¹‹å‰å°è¯•è¿‡`track mode`ï¼Œä½†æ˜¯ç”±äºåœ¨ç›®æ ‡ä¸¢å¤±ä¹‹åä¼šé‡æ–°åˆ†é…ä¸€ä¸ªidï¼Œå¹¶ä¸”ä¼¼ä¹å¹¶æ²¡æœ‰èµ·åˆ°è¿½è¸ªçš„åŠŸèƒ½ï¼Œæ‰€ä»¥æœ€åè¿˜æ˜¯é€‰æ‹©äº†`predict mode`

![alt text](image-5.png)