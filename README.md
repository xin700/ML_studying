# ä¸‹å­¦æœŸç¬¬ä¸€æ¬¡ä»»åŠ¡

##### å¤ç°éœ€è¦å°†deviceæ”¹ä¸ºcudaï¼Œæœ¬æœºä½¿ç”¨mps

## ä¸€.  MINISTæ‰‹å†™æ•°æ®é›†è¯†åˆ«

### ä½¿ç”¨æœ€å¼±çš„å…¨è¿æ¥ç½‘ç»œè¿›è¡Œè®­ç»ƒ

ä½¿ç”¨pytorchè‡ªå¸¦çš„ministæ•°æ®é›†APIè¿›è¡Œå¯¹äºæ•°æ®é›†çš„ä¸‹è½½

~~å¼€è¢‹å³é£Ÿ~~

```python
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)
```

å¯¹äºå…¨å±€å˜é‡çš„å®šä¹‰

```python
# 2. å®šä¹‰è¶…å‚æ•°
input_size = 784  # MNISTå›¾ç‰‡å¤§å°æ˜¯28x28
hidden_sizes = [128, 64]  # éšè—å±‚çš„å¤§å°
output_size = 10  # è¾“å‡ºçš„ç±»åˆ«æ•°ä¸º10ï¼Œåˆ†åˆ«å¯¹åº”0åˆ°9çš„æ•°å­—
num_epochs = 50  # è¿›è¡Œ5æ¬¡è®­ç»ƒè¿­ä»£
batch_size = 64  # æ¯æ‰¹æ¬¡å¤„ç†64å¼ å›¾ç‰‡
learning_rate = 0.001  # å­¦ä¹ ç‡è®¾ç½®ä¸º0.001

# 3. æ•°æ®å‡†å¤‡
transform = transforms.Compose([
    transforms.ToTensor(),  # å°†å›¾ç‰‡è½¬æ¢æˆPyTorchçš„Tensoræ ¼å¼
    transforms.Normalize((0.5,), (0.5,))  # æ ‡å‡†åŒ–å¤„ç†ï¼Œä»¥å‡å°æ¨¡å‹å¯¹æ•°æ®è§„æ¨¡çš„æ•æ„Ÿæ€§
])
```
å¯¹äºç¥ç»ç½‘ç»œå®šä¹‰çš„éƒ¨åˆ†ï¼Œç›´æ¥æš´åŠ›å…¨è¿æ¥ä¸‰å±‚

```python
 def __init__(self, input_size, hidden_sizes, output_size):
        super(NeuralNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_sizes[0])
        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])
        self.fc3 = nn.Linear(hidden_sizes[1], output_size)
        self.relu = nn.ReLU()
```
ä¼ æ’­å‡½æ•°ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°è¿›è¡Œæ¿€æ´»

```python
def forward(self, x):
    x = self.relu(self.fc1(x))
    x = self.relu(self.fc2(x))
    x = self.fc3(x)
    return x
```

è®­ç»ƒçš„æ•ˆæœä¼¼ä¹æ˜¯ä¸å·®çš„ï¼Œä½†æ˜¯é—®é¢˜å‡ºåœ¨äº†OJä¸Šè¯„æµ‹çš„æ—¶å€™ä¼¼ä¹model_load_error

æ¨¡å‹ä¿å­˜çš„é—®é¢˜ï¼Ÿä½†æ˜¯æ¥ä¸‹æ¥ä½¿ç”¨çš„cnnç½‘ç»œæ²¡æœ‰é—®é¢˜

### ä½¿ç”¨CNNç¥ç»ç½‘ç»œè¿›è¡Œå›¾åƒçš„åˆ†æ

```python
def __init__(self):
        super(Net, self).__init__()
        # å·ç§¯å±‚
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.batchnorm1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.batchnorm2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.batchnorm3 = nn.BatchNorm2d(128)
        # Dropoutå±‚
        self.dropout1 = nn.Dropout2d(0.25)
        self.dropout2 = nn.Dropout2d(0.5)
        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(128 * 7 * 7, 256) # æ›´æ­£å…¨è¿æ¥å±‚è¾“å…¥ç‰¹å¾æ•°
        self.fc2 = nn.Linear(256, 10)

    def forward(self, x):
        x = F.relu(self.batchnorm1(self.conv1(x)))
        x = F.relu(self.batchnorm2(self.conv2(x)))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.batchnorm3(self.conv3(x)))
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = self.dropout2(x)
        x = self.fc2(x)
        output = F.log_softmax(x, dim=1)
        return output
```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªå…·æœ‰å¤šä¸ªå·ç§¯å±‚ã€æ‰¹é‡å½’ä¸€åŒ–å±‚å’Œå…¨è¿æ¥å±‚çš„å·ç§¯ç¥ç»ç½‘ç»œ

`self.conv1` ç¬¬ä¸€ä¸ªå·ç§¯å±‚ï¼Œä½¿ç”¨ä¸€ä¸ªå•é€šé“çš„è¾“å…¥ï¼Œè¾“å‡º32ä¸ªç‰¹å¾æ˜ å°„ï¼Œå¹¶ä½¿ç”¨å¤§å°ä¸º3x3çš„å·ç§¯æ ¸å’Œ1çš„å¡«å……ï¼Œä»¥ç¡®ä¿åœ¨å·ç§¯æ“ä½œåè¾“å‡ºçš„ç»´åº¦ä¸å˜ã€‚

`self.batchnorm1` ç¬¬ä¸€ä¸ªæ‰¹é‡å½’ä¸€åŒ–å±‚ï¼Œå®ƒå¯¹åº”äºå·ç§¯å±‚conv1çš„è¾“å‡ºã€‚æ‰¹é‡å½’ä¸€åŒ–å¯ä»¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚

`self.dropout1`å’Œ`self.dropout2`æ˜¯Dropoutå±‚ï¼Œè¿™ä¸¤å±‚åˆ†åˆ«ä»¥0.25å’Œ0.50çš„æ¦‚ç‡æš‚æ—¶ä¸¢å¼ƒä¸€éƒ¨åˆ†ç‰¹å¾ï¼Œä»¥å‡å°‘æ¨¡å‹è¿‡æ‹Ÿåˆã€‚

æœ€åæ·»åŠ ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼Œçœ‹èµ·æ¥ä¼¼ä¹å¯ä»¥å¢åŠ å¯¹äºMINISTæ•°æ®é›†è¯†åˆ«çš„å‡†ç¡®åº¦

å¯¹ï¼Œ`çœ‹èµ·æ¥` `ä¼¼ä¹`

é‰´äºæˆ‘ç°åœ¨å¯¹äºå„ç§æœºå™¨å­¦ä¹ çš„ç»“æ„ä»…ä¿ç•™åœ¨æŠŠä¸åŒåŠŸèƒ½çš„â€œç§¯æœ¨â€æ­èµ·æ¥çš„é˜¶æ®µã€‚

æ‰€ä»¥è¿™ä¸ªç½‘ç»œçœ‹èµ·æ¥æŒºå¥½ï¼Œè¡¨ç°ä¹Ÿå°±ä¸€èˆ¬ã€‚

å¹¶ä¸”é—®é¢˜å‡ºåœ¨äº†è¿™ä¸ªç½‘ç»œä¼šéšç€è®­ç»ƒçš„epochå¢åŠ åˆ†æ•°é™ä½ã€‚ã€‚ã€‚

ğŸ˜­

## YOLOæ£€æµ‹æœºå™¨äºº