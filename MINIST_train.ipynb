{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T15:09:58.041904Z",
     "start_time": "2024-02-22T15:09:57.107731Z"
    }
   },
   "id": "29958e382f284e33"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/938], Loss: 0.5177665948867798\n",
      "Epoch [1/50], Step [200/938], Loss: 0.517952024936676\n",
      "Epoch [1/50], Step [300/938], Loss: 0.33616718649864197\n",
      "Epoch [1/50], Step [400/938], Loss: 0.2392079383134842\n",
      "Epoch [1/50], Step [500/938], Loss: 0.15293897688388824\n",
      "Epoch [1/50], Step [600/938], Loss: 0.37737101316452026\n",
      "Epoch [1/50], Step [700/938], Loss: 0.3027612268924713\n",
      "Epoch [1/50], Step [800/938], Loss: 0.14483892917633057\n",
      "Epoch [1/50], Step [900/938], Loss: 0.2886595129966736\n",
      "Epoch [2/50], Step [100/938], Loss: 0.20182228088378906\n",
      "Epoch [2/50], Step [200/938], Loss: 0.07629455626010895\n",
      "Epoch [2/50], Step [300/938], Loss: 0.36338475346565247\n",
      "Epoch [2/50], Step [400/938], Loss: 0.1835208237171173\n",
      "Epoch [2/50], Step [500/938], Loss: 0.2499009370803833\n",
      "Epoch [2/50], Step [600/938], Loss: 0.1669710874557495\n",
      "Epoch [2/50], Step [700/938], Loss: 0.3042776584625244\n",
      "Epoch [2/50], Step [800/938], Loss: 0.22158721089363098\n",
      "Epoch [2/50], Step [900/938], Loss: 0.06121711805462837\n",
      "Epoch [3/50], Step [100/938], Loss: 0.22665517032146454\n",
      "Epoch [3/50], Step [200/938], Loss: 0.08375069499015808\n",
      "Epoch [3/50], Step [300/938], Loss: 0.13046133518218994\n",
      "Epoch [3/50], Step [400/938], Loss: 0.24229037761688232\n",
      "Epoch [3/50], Step [500/938], Loss: 0.14730362594127655\n",
      "Epoch [3/50], Step [600/938], Loss: 0.4005014896392822\n",
      "Epoch [3/50], Step [700/938], Loss: 0.1973811686038971\n",
      "Epoch [3/50], Step [800/938], Loss: 0.025926094502210617\n",
      "Epoch [3/50], Step [900/938], Loss: 0.1417102813720703\n",
      "Epoch [4/50], Step [100/938], Loss: 0.04726886376738548\n",
      "Epoch [4/50], Step [200/938], Loss: 0.17248527705669403\n",
      "Epoch [4/50], Step [300/938], Loss: 0.15721577405929565\n",
      "Epoch [4/50], Step [400/938], Loss: 0.09891628473997116\n",
      "Epoch [4/50], Step [500/938], Loss: 0.06974473595619202\n",
      "Epoch [4/50], Step [600/938], Loss: 0.0904136672616005\n",
      "Epoch [4/50], Step [700/938], Loss: 0.09952430427074432\n",
      "Epoch [4/50], Step [800/938], Loss: 0.17750295996665955\n",
      "Epoch [4/50], Step [900/938], Loss: 0.06165286898612976\n",
      "Epoch [5/50], Step [100/938], Loss: 0.16344255208969116\n",
      "Epoch [5/50], Step [200/938], Loss: 0.06291861832141876\n",
      "Epoch [5/50], Step [300/938], Loss: 0.07305857539176941\n",
      "Epoch [5/50], Step [400/938], Loss: 0.08129263669252396\n",
      "Epoch [5/50], Step [500/938], Loss: 0.07820568978786469\n",
      "Epoch [5/50], Step [600/938], Loss: 0.023317186161875725\n",
      "Epoch [5/50], Step [700/938], Loss: 0.11257556825876236\n",
      "Epoch [5/50], Step [800/938], Loss: 0.10225870460271835\n",
      "Epoch [5/50], Step [900/938], Loss: 0.1439666748046875\n",
      "Epoch [6/50], Step [100/938], Loss: 0.09553054720163345\n",
      "Epoch [6/50], Step [200/938], Loss: 0.12456583976745605\n",
      "Epoch [6/50], Step [300/938], Loss: 0.091292604804039\n",
      "Epoch [6/50], Step [400/938], Loss: 0.1086975485086441\n",
      "Epoch [6/50], Step [500/938], Loss: 0.08891651779413223\n",
      "Epoch [6/50], Step [600/938], Loss: 0.06922341138124466\n",
      "Epoch [6/50], Step [700/938], Loss: 0.04424766078591347\n",
      "Epoch [6/50], Step [800/938], Loss: 0.015899451449513435\n",
      "Epoch [6/50], Step [900/938], Loss: 0.09649079293012619\n",
      "Epoch [7/50], Step [100/938], Loss: 0.03132227435708046\n",
      "Epoch [7/50], Step [200/938], Loss: 0.011292940936982632\n",
      "Epoch [7/50], Step [300/938], Loss: 0.09106633067131042\n",
      "Epoch [7/50], Step [400/938], Loss: 0.022948449477553368\n",
      "Epoch [7/50], Step [500/938], Loss: 0.016567368060350418\n",
      "Epoch [7/50], Step [600/938], Loss: 0.03001941367983818\n",
      "Epoch [7/50], Step [700/938], Loss: 0.11923046410083771\n",
      "Epoch [7/50], Step [800/938], Loss: 0.010602437891066074\n",
      "Epoch [7/50], Step [900/938], Loss: 0.07584384828805923\n",
      "Epoch [8/50], Step [100/938], Loss: 0.021967848762869835\n",
      "Epoch [8/50], Step [200/938], Loss: 0.09976324439048767\n",
      "Epoch [8/50], Step [300/938], Loss: 0.0072089917957782745\n",
      "Epoch [8/50], Step [400/938], Loss: 0.08402072638273239\n",
      "Epoch [8/50], Step [500/938], Loss: 0.020808791741728783\n",
      "Epoch [8/50], Step [600/938], Loss: 0.010796645656228065\n",
      "Epoch [8/50], Step [700/938], Loss: 0.025038594380021095\n",
      "Epoch [8/50], Step [800/938], Loss: 0.015268322080373764\n",
      "Epoch [8/50], Step [900/938], Loss: 0.0484435148537159\n",
      "Epoch [9/50], Step [100/938], Loss: 0.046830914914608\n",
      "Epoch [9/50], Step [200/938], Loss: 0.003888273611664772\n",
      "Epoch [9/50], Step [300/938], Loss: 0.1324630230665207\n",
      "Epoch [9/50], Step [400/938], Loss: 0.07311751693487167\n",
      "Epoch [9/50], Step [500/938], Loss: 0.01295645534992218\n",
      "Epoch [9/50], Step [600/938], Loss: 0.15697717666625977\n",
      "Epoch [9/50], Step [700/938], Loss: 0.04077587649226189\n",
      "Epoch [9/50], Step [800/938], Loss: 0.07132086902856827\n",
      "Epoch [9/50], Step [900/938], Loss: 0.019318047910928726\n",
      "Epoch [10/50], Step [100/938], Loss: 0.010370436124503613\n",
      "Epoch [10/50], Step [200/938], Loss: 0.04504062980413437\n",
      "Epoch [10/50], Step [300/938], Loss: 0.012144188396632671\n",
      "Epoch [10/50], Step [400/938], Loss: 0.1226273626089096\n",
      "Epoch [10/50], Step [500/938], Loss: 0.03423565253615379\n",
      "Epoch [10/50], Step [600/938], Loss: 0.06394405663013458\n",
      "Epoch [10/50], Step [700/938], Loss: 0.01640726625919342\n",
      "Epoch [10/50], Step [800/938], Loss: 0.1526690125465393\n",
      "Epoch [10/50], Step [900/938], Loss: 0.0032089841552078724\n",
      "Epoch [11/50], Step [100/938], Loss: 0.07674485445022583\n",
      "Epoch [11/50], Step [200/938], Loss: 0.1217045858502388\n",
      "Epoch [11/50], Step [300/938], Loss: 0.11260098218917847\n",
      "Epoch [11/50], Step [400/938], Loss: 0.02929818071424961\n",
      "Epoch [11/50], Step [500/938], Loss: 0.04807901382446289\n",
      "Epoch [11/50], Step [600/938], Loss: 0.016835857182741165\n",
      "Epoch [11/50], Step [700/938], Loss: 0.05272800847887993\n",
      "Epoch [11/50], Step [800/938], Loss: 0.04625694081187248\n",
      "Epoch [11/50], Step [900/938], Loss: 0.06639169901609421\n",
      "Epoch [12/50], Step [100/938], Loss: 0.017499808222055435\n",
      "Epoch [12/50], Step [200/938], Loss: 0.01177377998828888\n",
      "Epoch [12/50], Step [300/938], Loss: 0.22309228777885437\n",
      "Epoch [12/50], Step [400/938], Loss: 0.067770816385746\n",
      "Epoch [12/50], Step [500/938], Loss: 0.038712866604328156\n",
      "Epoch [12/50], Step [600/938], Loss: 0.09286203235387802\n",
      "Epoch [12/50], Step [700/938], Loss: 0.024821653962135315\n",
      "Epoch [12/50], Step [800/938], Loss: 0.013740510679781437\n",
      "Epoch [12/50], Step [900/938], Loss: 0.009936352260410786\n",
      "Epoch [13/50], Step [100/938], Loss: 0.023944465443491936\n",
      "Epoch [13/50], Step [200/938], Loss: 0.021564526483416557\n",
      "Epoch [13/50], Step [300/938], Loss: 0.02288651652634144\n",
      "Epoch [13/50], Step [400/938], Loss: 0.03726479411125183\n",
      "Epoch [13/50], Step [500/938], Loss: 0.10431113094091415\n",
      "Epoch [13/50], Step [600/938], Loss: 0.06648488342761993\n",
      "Epoch [13/50], Step [700/938], Loss: 0.013104835525155067\n",
      "Epoch [13/50], Step [800/938], Loss: 0.007130298297852278\n",
      "Epoch [13/50], Step [900/938], Loss: 0.00541277090087533\n",
      "Epoch [14/50], Step [100/938], Loss: 0.08707604557275772\n",
      "Epoch [14/50], Step [200/938], Loss: 0.08320927619934082\n",
      "Epoch [14/50], Step [300/938], Loss: 0.016426391899585724\n",
      "Epoch [14/50], Step [400/938], Loss: 0.0030728988349437714\n",
      "Epoch [14/50], Step [500/938], Loss: 0.011386750265955925\n",
      "Epoch [14/50], Step [600/938], Loss: 0.023566177114844322\n",
      "Epoch [14/50], Step [700/938], Loss: 0.18517132103443146\n",
      "Epoch [14/50], Step [800/938], Loss: 0.06462375819683075\n",
      "Epoch [14/50], Step [900/938], Loss: 0.005514542572200298\n",
      "Epoch [15/50], Step [100/938], Loss: 0.10240864753723145\n",
      "Epoch [15/50], Step [200/938], Loss: 0.016977891325950623\n",
      "Epoch [15/50], Step [300/938], Loss: 0.0074652452021837234\n",
      "Epoch [15/50], Step [400/938], Loss: 0.07930324971675873\n",
      "Epoch [15/50], Step [500/938], Loss: 0.03916235268115997\n",
      "Epoch [15/50], Step [600/938], Loss: 0.0010405867360532284\n",
      "Epoch [15/50], Step [700/938], Loss: 0.036208461970090866\n",
      "Epoch [15/50], Step [800/938], Loss: 0.003497534431517124\n",
      "Epoch [15/50], Step [900/938], Loss: 0.055910080671310425\n",
      "Epoch [16/50], Step [100/938], Loss: 0.006605931092053652\n",
      "Epoch [16/50], Step [200/938], Loss: 0.013131987303495407\n",
      "Epoch [16/50], Step [300/938], Loss: 0.0009262678795494139\n",
      "Epoch [16/50], Step [400/938], Loss: 0.004941338207572699\n",
      "Epoch [16/50], Step [500/938], Loss: 0.004478889983147383\n",
      "Epoch [16/50], Step [600/938], Loss: 0.010520562529563904\n",
      "Epoch [16/50], Step [700/938], Loss: 0.03771151229739189\n",
      "Epoch [16/50], Step [800/938], Loss: 0.0327199324965477\n",
      "Epoch [16/50], Step [900/938], Loss: 0.13194188475608826\n",
      "Epoch [17/50], Step [100/938], Loss: 0.003547081956639886\n",
      "Epoch [17/50], Step [200/938], Loss: 0.013047611340880394\n",
      "Epoch [17/50], Step [300/938], Loss: 0.040367644280195236\n",
      "Epoch [17/50], Step [400/938], Loss: 0.03778829425573349\n",
      "Epoch [17/50], Step [500/938], Loss: 0.011353015899658203\n",
      "Epoch [17/50], Step [600/938], Loss: 0.028302501887083054\n",
      "Epoch [17/50], Step [700/938], Loss: 0.005914065986871719\n",
      "Epoch [17/50], Step [800/938], Loss: 0.024329399690032005\n",
      "Epoch [17/50], Step [900/938], Loss: 0.009412513114511967\n",
      "Epoch [18/50], Step [100/938], Loss: 0.047208137810230255\n",
      "Epoch [18/50], Step [200/938], Loss: 0.05221609026193619\n",
      "Epoch [18/50], Step [300/938], Loss: 0.07375794649124146\n",
      "Epoch [18/50], Step [400/938], Loss: 0.03578135371208191\n",
      "Epoch [18/50], Step [500/938], Loss: 0.0023414059542119503\n",
      "Epoch [18/50], Step [600/938], Loss: 0.0018819926772266626\n",
      "Epoch [18/50], Step [700/938], Loss: 0.002226707525551319\n",
      "Epoch [18/50], Step [800/938], Loss: 0.0666169747710228\n",
      "Epoch [18/50], Step [900/938], Loss: 0.0004922539810650051\n",
      "Epoch [19/50], Step [100/938], Loss: 0.005431107711046934\n",
      "Epoch [19/50], Step [200/938], Loss: 0.08928629755973816\n",
      "Epoch [19/50], Step [300/938], Loss: 0.045590683817863464\n",
      "Epoch [19/50], Step [400/938], Loss: 0.032553140074014664\n",
      "Epoch [19/50], Step [500/938], Loss: 0.0013819627929478884\n",
      "Epoch [19/50], Step [600/938], Loss: 0.003994571045041084\n",
      "Epoch [19/50], Step [700/938], Loss: 0.024927470833063126\n",
      "Epoch [19/50], Step [800/938], Loss: 0.028493644669651985\n",
      "Epoch [19/50], Step [900/938], Loss: 0.014734901487827301\n",
      "Epoch [20/50], Step [100/938], Loss: 0.027276938781142235\n",
      "Epoch [20/50], Step [200/938], Loss: 0.002426497172564268\n",
      "Epoch [20/50], Step [300/938], Loss: 0.037786319851875305\n",
      "Epoch [20/50], Step [400/938], Loss: 0.015073934569954872\n",
      "Epoch [20/50], Step [500/938], Loss: 0.008125493302941322\n",
      "Epoch [20/50], Step [600/938], Loss: 0.010582995600998402\n",
      "Epoch [20/50], Step [700/938], Loss: 0.07898910343647003\n",
      "Epoch [20/50], Step [800/938], Loss: 0.045598313212394714\n",
      "Epoch [20/50], Step [900/938], Loss: 0.0015338766388595104\n",
      "Epoch [21/50], Step [100/938], Loss: 0.016900300979614258\n",
      "Epoch [21/50], Step [200/938], Loss: 0.13790133595466614\n",
      "Epoch [21/50], Step [300/938], Loss: 0.023261472582817078\n",
      "Epoch [21/50], Step [400/938], Loss: 0.005739359185099602\n",
      "Epoch [21/50], Step [500/938], Loss: 0.022328024730086327\n",
      "Epoch [21/50], Step [600/938], Loss: 0.01914464682340622\n",
      "Epoch [21/50], Step [700/938], Loss: 0.04488427937030792\n",
      "Epoch [21/50], Step [800/938], Loss: 0.043275266885757446\n",
      "Epoch [21/50], Step [900/938], Loss: 0.13977494835853577\n",
      "Epoch [22/50], Step [100/938], Loss: 0.002023175125941634\n",
      "Epoch [22/50], Step [200/938], Loss: 0.002210659207776189\n",
      "Epoch [22/50], Step [300/938], Loss: 0.02028912678360939\n",
      "Epoch [22/50], Step [400/938], Loss: 0.03442147746682167\n",
      "Epoch [22/50], Step [500/938], Loss: 0.040370307862758636\n",
      "Epoch [22/50], Step [600/938], Loss: 0.0008067763992585242\n",
      "Epoch [22/50], Step [700/938], Loss: 0.013874543830752373\n",
      "Epoch [22/50], Step [800/938], Loss: 0.029664969071745872\n",
      "Epoch [22/50], Step [900/938], Loss: 0.0364084392786026\n",
      "Epoch [23/50], Step [100/938], Loss: 0.043682754039764404\n",
      "Epoch [23/50], Step [200/938], Loss: 0.024801604449748993\n",
      "Epoch [23/50], Step [300/938], Loss: 0.10398127138614655\n",
      "Epoch [23/50], Step [400/938], Loss: 0.00023709148808848113\n",
      "Epoch [23/50], Step [500/938], Loss: 0.012660529464483261\n",
      "Epoch [23/50], Step [600/938], Loss: 0.089659184217453\n",
      "Epoch [23/50], Step [700/938], Loss: 0.024215079843997955\n",
      "Epoch [23/50], Step [800/938], Loss: 0.053332116454839706\n",
      "Epoch [23/50], Step [900/938], Loss: 0.0019571962766349316\n",
      "Epoch [24/50], Step [100/938], Loss: 0.02989424578845501\n",
      "Epoch [24/50], Step [200/938], Loss: 0.00023085052089300007\n",
      "Epoch [24/50], Step [300/938], Loss: 0.05445275455713272\n",
      "Epoch [24/50], Step [400/938], Loss: 0.03264378011226654\n",
      "Epoch [24/50], Step [500/938], Loss: 0.0038230384234339\n",
      "Epoch [24/50], Step [600/938], Loss: 0.04096096381545067\n",
      "Epoch [24/50], Step [700/938], Loss: 0.08253751695156097\n",
      "Epoch [24/50], Step [800/938], Loss: 0.08779473602771759\n",
      "Epoch [24/50], Step [900/938], Loss: 0.006068061105906963\n",
      "Epoch [25/50], Step [100/938], Loss: 0.0007339058793149889\n",
      "Epoch [25/50], Step [200/938], Loss: 0.0076630148105323315\n",
      "Epoch [25/50], Step [300/938], Loss: 0.05470918118953705\n",
      "Epoch [25/50], Step [400/938], Loss: 0.020545776933431625\n",
      "Epoch [25/50], Step [500/938], Loss: 0.006326006259769201\n",
      "Epoch [25/50], Step [600/938], Loss: 0.02795146033167839\n",
      "Epoch [25/50], Step [700/938], Loss: 0.02021261490881443\n",
      "Epoch [25/50], Step [800/938], Loss: 0.008407866582274437\n",
      "Epoch [25/50], Step [900/938], Loss: 0.04944746568799019\n",
      "Epoch [26/50], Step [100/938], Loss: 0.001895504305139184\n",
      "Epoch [26/50], Step [200/938], Loss: 0.008278424851596355\n",
      "Epoch [26/50], Step [300/938], Loss: 0.010791384615004063\n",
      "Epoch [26/50], Step [400/938], Loss: 0.0035424083471298218\n",
      "Epoch [26/50], Step [500/938], Loss: 0.007041282951831818\n",
      "Epoch [26/50], Step [600/938], Loss: 0.024345193058252335\n",
      "Epoch [26/50], Step [700/938], Loss: 0.011722219176590443\n",
      "Epoch [26/50], Step [800/938], Loss: 0.00260826270096004\n",
      "Epoch [26/50], Step [900/938], Loss: 0.0013550184667110443\n",
      "Epoch [27/50], Step [100/938], Loss: 0.004127885214984417\n",
      "Epoch [27/50], Step [200/938], Loss: 0.0019987826235592365\n",
      "Epoch [27/50], Step [300/938], Loss: 0.07123032957315445\n",
      "Epoch [27/50], Step [400/938], Loss: 0.021756693720817566\n",
      "Epoch [27/50], Step [500/938], Loss: 0.03422491252422333\n",
      "Epoch [27/50], Step [600/938], Loss: 0.010539136826992035\n",
      "Epoch [27/50], Step [700/938], Loss: 0.0031142730731517076\n",
      "Epoch [27/50], Step [800/938], Loss: 0.00659832963719964\n",
      "Epoch [27/50], Step [900/938], Loss: 0.007107615936547518\n",
      "Epoch [28/50], Step [100/938], Loss: 0.01354846078902483\n",
      "Epoch [28/50], Step [200/938], Loss: 0.05291258543729782\n",
      "Epoch [28/50], Step [300/938], Loss: 0.003181674750521779\n",
      "Epoch [28/50], Step [400/938], Loss: 0.0007949169958010316\n",
      "Epoch [28/50], Step [500/938], Loss: 0.0024882727302610874\n",
      "Epoch [28/50], Step [600/938], Loss: 0.01776915229856968\n",
      "Epoch [28/50], Step [700/938], Loss: 0.0034421547316014767\n",
      "Epoch [28/50], Step [800/938], Loss: 0.0003796603996306658\n",
      "Epoch [28/50], Step [900/938], Loss: 0.0253930501639843\n",
      "Epoch [29/50], Step [100/938], Loss: 0.0016898176399990916\n",
      "Epoch [29/50], Step [200/938], Loss: 0.0017039318336173892\n",
      "Epoch [29/50], Step [300/938], Loss: 0.04755046218633652\n",
      "Epoch [29/50], Step [400/938], Loss: 0.021124891936779022\n",
      "Epoch [29/50], Step [500/938], Loss: 0.0009804299334064126\n",
      "Epoch [29/50], Step [600/938], Loss: 0.0008827632409520447\n",
      "Epoch [29/50], Step [700/938], Loss: 0.005448890384286642\n",
      "Epoch [29/50], Step [800/938], Loss: 0.08436916768550873\n",
      "Epoch [29/50], Step [900/938], Loss: 0.0002941855345852673\n",
      "Epoch [30/50], Step [100/938], Loss: 0.003919238690286875\n",
      "Epoch [30/50], Step [200/938], Loss: 0.000955978874117136\n",
      "Epoch [30/50], Step [300/938], Loss: 0.0008497614180669188\n",
      "Epoch [30/50], Step [400/938], Loss: 0.0020673139952123165\n",
      "Epoch [30/50], Step [500/938], Loss: 0.05828161537647247\n",
      "Epoch [30/50], Step [600/938], Loss: 0.010024499148130417\n",
      "Epoch [30/50], Step [700/938], Loss: 0.00187053217086941\n",
      "Epoch [30/50], Step [800/938], Loss: 0.11307738721370697\n",
      "Epoch [30/50], Step [900/938], Loss: 0.0004890866111963987\n",
      "Epoch [31/50], Step [100/938], Loss: 0.0016000926261767745\n",
      "Epoch [31/50], Step [200/938], Loss: 0.1695898473262787\n",
      "Epoch [31/50], Step [300/938], Loss: 0.000548773561604321\n",
      "Epoch [31/50], Step [400/938], Loss: 0.0014782140497118235\n",
      "Epoch [31/50], Step [500/938], Loss: 0.0013569429283961654\n",
      "Epoch [31/50], Step [600/938], Loss: 0.02663780190050602\n",
      "Epoch [31/50], Step [700/938], Loss: 0.017438653856515884\n",
      "Epoch [31/50], Step [800/938], Loss: 0.0003276189381722361\n",
      "Epoch [31/50], Step [900/938], Loss: 0.020467517897486687\n",
      "Epoch [32/50], Step [100/938], Loss: 0.0007335587870329618\n",
      "Epoch [32/50], Step [200/938], Loss: 0.00021090477821417153\n",
      "Epoch [32/50], Step [300/938], Loss: 0.002316383644938469\n",
      "Epoch [32/50], Step [400/938], Loss: 0.022384390234947205\n",
      "Epoch [32/50], Step [500/938], Loss: 0.01795131340622902\n",
      "Epoch [32/50], Step [600/938], Loss: 0.01668791100382805\n",
      "Epoch [32/50], Step [700/938], Loss: 0.005274347495287657\n",
      "Epoch [32/50], Step [800/938], Loss: 0.009313944727182388\n",
      "Epoch [32/50], Step [900/938], Loss: 0.0005124883609823883\n",
      "Epoch [33/50], Step [100/938], Loss: 0.073630191385746\n",
      "Epoch [33/50], Step [200/938], Loss: 0.09381473064422607\n",
      "Epoch [33/50], Step [300/938], Loss: 0.0002458243689034134\n",
      "Epoch [33/50], Step [400/938], Loss: 0.001978738233447075\n",
      "Epoch [33/50], Step [500/938], Loss: 0.006956853903830051\n",
      "Epoch [33/50], Step [600/938], Loss: 0.05456630140542984\n",
      "Epoch [33/50], Step [700/938], Loss: 0.0014192962553352118\n",
      "Epoch [33/50], Step [800/938], Loss: 0.052038587629795074\n",
      "Epoch [33/50], Step [900/938], Loss: 0.024610931053757668\n",
      "Epoch [34/50], Step [100/938], Loss: 0.08955850452184677\n",
      "Epoch [34/50], Step [200/938], Loss: 0.005880563985556364\n",
      "Epoch [34/50], Step [300/938], Loss: 0.044973548501729965\n",
      "Epoch [34/50], Step [400/938], Loss: 0.007514298893511295\n",
      "Epoch [34/50], Step [500/938], Loss: 0.0002491431951057166\n",
      "Epoch [34/50], Step [600/938], Loss: 0.008106578141450882\n",
      "Epoch [34/50], Step [700/938], Loss: 0.01937740109860897\n",
      "Epoch [34/50], Step [800/938], Loss: 0.003668205114081502\n",
      "Epoch [34/50], Step [900/938], Loss: 0.0021540678571909666\n",
      "Epoch [35/50], Step [100/938], Loss: 0.010356857441365719\n",
      "Epoch [35/50], Step [200/938], Loss: 0.0048407213762402534\n",
      "Epoch [35/50], Step [300/938], Loss: 0.0034916915465146303\n",
      "Epoch [35/50], Step [400/938], Loss: 0.00010587974975351244\n",
      "Epoch [35/50], Step [500/938], Loss: 0.0006041091401129961\n",
      "Epoch [35/50], Step [600/938], Loss: 0.0183138195425272\n",
      "Epoch [35/50], Step [700/938], Loss: 0.035220902413129807\n",
      "Epoch [35/50], Step [800/938], Loss: 0.0800611600279808\n",
      "Epoch [35/50], Step [900/938], Loss: 0.004016445949673653\n",
      "Epoch [36/50], Step [100/938], Loss: 0.0015622999053448439\n",
      "Epoch [36/50], Step [200/938], Loss: 0.02855573408305645\n",
      "Epoch [36/50], Step [300/938], Loss: 0.16982370615005493\n",
      "Epoch [36/50], Step [400/938], Loss: 0.008285675197839737\n",
      "Epoch [36/50], Step [500/938], Loss: 0.0028385943733155727\n",
      "Epoch [36/50], Step [600/938], Loss: 5.904133649892174e-05\n",
      "Epoch [36/50], Step [700/938], Loss: 0.007909031584858894\n",
      "Epoch [36/50], Step [800/938], Loss: 0.014612262137234211\n",
      "Epoch [36/50], Step [900/938], Loss: 0.04700716212391853\n",
      "Epoch [37/50], Step [100/938], Loss: 0.00046875898260623217\n",
      "Epoch [37/50], Step [200/938], Loss: 0.03935873508453369\n",
      "Epoch [37/50], Step [300/938], Loss: 0.00195861142128706\n",
      "Epoch [37/50], Step [400/938], Loss: 0.0001959750516107306\n",
      "Epoch [37/50], Step [500/938], Loss: 0.0020818086341023445\n",
      "Epoch [37/50], Step [600/938], Loss: 0.13876661658287048\n",
      "Epoch [37/50], Step [700/938], Loss: 0.00014274459681473672\n",
      "Epoch [37/50], Step [800/938], Loss: 0.0661032572388649\n",
      "Epoch [37/50], Step [900/938], Loss: 0.09941425919532776\n",
      "Epoch [38/50], Step [100/938], Loss: 0.00041165685979649425\n",
      "Epoch [38/50], Step [200/938], Loss: 0.019829565659165382\n",
      "Epoch [38/50], Step [300/938], Loss: 0.0012327959993854165\n",
      "Epoch [38/50], Step [400/938], Loss: 0.014680525287985802\n",
      "Epoch [38/50], Step [500/938], Loss: 0.008243652991950512\n",
      "Epoch [38/50], Step [600/938], Loss: 0.05437730625271797\n",
      "Epoch [38/50], Step [700/938], Loss: 0.0012828155886381865\n",
      "Epoch [38/50], Step [800/938], Loss: 0.012256810441613197\n",
      "Epoch [38/50], Step [900/938], Loss: 0.011430738493800163\n",
      "Epoch [39/50], Step [100/938], Loss: 0.00020264917111489922\n",
      "Epoch [39/50], Step [200/938], Loss: 0.0012181990314275026\n",
      "Epoch [39/50], Step [300/938], Loss: 0.0006562789785675704\n",
      "Epoch [39/50], Step [400/938], Loss: 0.0007940115174278617\n",
      "Epoch [39/50], Step [500/938], Loss: 1.7032927644322626e-05\n",
      "Epoch [39/50], Step [600/938], Loss: 0.0008345533860847354\n",
      "Epoch [39/50], Step [700/938], Loss: 0.010609472170472145\n",
      "Epoch [39/50], Step [800/938], Loss: 0.0004860523040406406\n",
      "Epoch [39/50], Step [900/938], Loss: 0.11039026081562042\n",
      "Epoch [40/50], Step [100/938], Loss: 0.05095183476805687\n",
      "Epoch [40/50], Step [200/938], Loss: 0.008323333226144314\n",
      "Epoch [40/50], Step [300/938], Loss: 0.008190956898033619\n",
      "Epoch [40/50], Step [400/938], Loss: 0.08146683871746063\n",
      "Epoch [40/50], Step [500/938], Loss: 8.383393287658691e-05\n",
      "Epoch [40/50], Step [600/938], Loss: 0.11815009266138077\n",
      "Epoch [40/50], Step [700/938], Loss: 0.04214968904852867\n",
      "Epoch [40/50], Step [800/938], Loss: 0.00040522689232602715\n",
      "Epoch [40/50], Step [900/938], Loss: 0.002449784427881241\n",
      "Epoch [41/50], Step [100/938], Loss: 0.010921230539679527\n",
      "Epoch [41/50], Step [200/938], Loss: 0.006846565753221512\n",
      "Epoch [41/50], Step [300/938], Loss: 9.926324855769053e-05\n",
      "Epoch [41/50], Step [400/938], Loss: 0.00033047294709831476\n",
      "Epoch [41/50], Step [500/938], Loss: 0.002771435072645545\n",
      "Epoch [41/50], Step [600/938], Loss: 0.006274896673858166\n",
      "Epoch [41/50], Step [700/938], Loss: 0.001876907772384584\n",
      "Epoch [41/50], Step [800/938], Loss: 0.004320564679801464\n",
      "Epoch [41/50], Step [900/938], Loss: 0.014553270302712917\n",
      "Epoch [42/50], Step [100/938], Loss: 0.0006019168067723513\n",
      "Epoch [42/50], Step [200/938], Loss: 7.76224333094433e-05\n",
      "Epoch [42/50], Step [300/938], Loss: 0.00023140499251894653\n",
      "Epoch [42/50], Step [400/938], Loss: 0.003318206872791052\n",
      "Epoch [42/50], Step [500/938], Loss: 0.0009658479830250144\n",
      "Epoch [42/50], Step [600/938], Loss: 0.002026350237429142\n",
      "Epoch [42/50], Step [700/938], Loss: 0.0002599390863906592\n",
      "Epoch [42/50], Step [800/938], Loss: 0.00017977097013499588\n",
      "Epoch [42/50], Step [900/938], Loss: 0.000490205769892782\n",
      "Epoch [43/50], Step [100/938], Loss: 0.002038470935076475\n",
      "Epoch [43/50], Step [200/938], Loss: 0.0017434736946597695\n",
      "Epoch [43/50], Step [300/938], Loss: 4.640191764337942e-05\n",
      "Epoch [43/50], Step [400/938], Loss: 0.0011051122564822435\n",
      "Epoch [43/50], Step [500/938], Loss: 0.09612355381250381\n",
      "Epoch [43/50], Step [600/938], Loss: 8.235582208726555e-05\n",
      "Epoch [43/50], Step [700/938], Loss: 0.0015920730074867606\n",
      "Epoch [43/50], Step [800/938], Loss: 0.006815542466938496\n",
      "Epoch [43/50], Step [900/938], Loss: 0.011741571128368378\n",
      "Epoch [44/50], Step [100/938], Loss: 0.003611344378441572\n",
      "Epoch [44/50], Step [200/938], Loss: 0.0015538848238065839\n",
      "Epoch [44/50], Step [300/938], Loss: 0.027438988909125328\n",
      "Epoch [44/50], Step [400/938], Loss: 0.018220672383904457\n",
      "Epoch [44/50], Step [500/938], Loss: 0.010149562731385231\n",
      "Epoch [44/50], Step [600/938], Loss: 0.0024805841967463493\n",
      "Epoch [44/50], Step [700/938], Loss: 1.2909185898024589e-05\n",
      "Epoch [44/50], Step [800/938], Loss: 2.9258762879180722e-05\n",
      "Epoch [44/50], Step [900/938], Loss: 0.0403003916144371\n",
      "Epoch [45/50], Step [100/938], Loss: 0.0006788562750443816\n",
      "Epoch [45/50], Step [200/938], Loss: 0.022756002843379974\n",
      "Epoch [45/50], Step [300/938], Loss: 0.026800157502293587\n",
      "Epoch [45/50], Step [400/938], Loss: 0.011820416897535324\n",
      "Epoch [45/50], Step [500/938], Loss: 0.07520794123411179\n",
      "Epoch [45/50], Step [600/938], Loss: 0.04211099073290825\n",
      "Epoch [45/50], Step [700/938], Loss: 0.0007844942156225443\n",
      "Epoch [45/50], Step [800/938], Loss: 0.0034333118237555027\n",
      "Epoch [45/50], Step [900/938], Loss: 0.030065713450312614\n",
      "Epoch [46/50], Step [100/938], Loss: 0.007118449546396732\n",
      "Epoch [46/50], Step [200/938], Loss: 0.02042412757873535\n",
      "Epoch [46/50], Step [300/938], Loss: 0.0007196718943305314\n",
      "Epoch [46/50], Step [400/938], Loss: 0.02659282088279724\n",
      "Epoch [46/50], Step [500/938], Loss: 0.1189405545592308\n",
      "Epoch [46/50], Step [600/938], Loss: 0.00023965415311977267\n",
      "Epoch [46/50], Step [700/938], Loss: 0.00036918491241522133\n",
      "Epoch [46/50], Step [800/938], Loss: 0.09551334381103516\n",
      "Epoch [46/50], Step [900/938], Loss: 0.0028518689796328545\n",
      "Epoch [47/50], Step [100/938], Loss: 0.0036723848897963762\n",
      "Epoch [47/50], Step [200/938], Loss: 0.0010381394531577826\n",
      "Epoch [47/50], Step [300/938], Loss: 0.008523049764335155\n",
      "Epoch [47/50], Step [400/938], Loss: 0.029058394953608513\n",
      "Epoch [47/50], Step [500/938], Loss: 0.00010086335532832891\n",
      "Epoch [47/50], Step [600/938], Loss: 0.0016392880352213979\n",
      "Epoch [47/50], Step [700/938], Loss: 0.06433429569005966\n",
      "Epoch [47/50], Step [800/938], Loss: 0.008300412446260452\n",
      "Epoch [47/50], Step [900/938], Loss: 0.0009079175069928169\n",
      "Epoch [48/50], Step [100/938], Loss: 0.010329224169254303\n",
      "Epoch [48/50], Step [200/938], Loss: 0.038488078862428665\n",
      "Epoch [48/50], Step [300/938], Loss: 0.027083788067102432\n",
      "Epoch [48/50], Step [400/938], Loss: 0.0003612821165006608\n",
      "Epoch [48/50], Step [500/938], Loss: 1.3569572729466017e-05\n",
      "Epoch [48/50], Step [600/938], Loss: 0.002664269180968404\n",
      "Epoch [48/50], Step [700/938], Loss: 1.9707909814314917e-05\n",
      "Epoch [48/50], Step [800/938], Loss: 0.006039369851350784\n",
      "Epoch [48/50], Step [900/938], Loss: 0.0001989890733966604\n",
      "Epoch [49/50], Step [100/938], Loss: 0.0007013452122919261\n",
      "Epoch [49/50], Step [200/938], Loss: 0.0007685665041208267\n",
      "Epoch [49/50], Step [300/938], Loss: 0.046650614589452744\n",
      "Epoch [49/50], Step [400/938], Loss: 0.0022786802146583796\n",
      "Epoch [49/50], Step [500/938], Loss: 0.0005302373319864273\n",
      "Epoch [49/50], Step [600/938], Loss: 0.0028036944568157196\n",
      "Epoch [49/50], Step [700/938], Loss: 0.10447711497545242\n",
      "Epoch [49/50], Step [800/938], Loss: 0.013914977200329304\n",
      "Epoch [49/50], Step [900/938], Loss: 0.0009944804478436708\n",
      "Epoch [50/50], Step [100/938], Loss: 0.0002704397775232792\n",
      "Epoch [50/50], Step [200/938], Loss: 0.00022642454132437706\n",
      "Epoch [50/50], Step [300/938], Loss: 5.826033520861529e-05\n",
      "Epoch [50/50], Step [400/938], Loss: 0.0200125090777874\n",
      "Epoch [50/50], Step [500/938], Loss: 0.04073930159211159\n",
      "Epoch [50/50], Step [600/938], Loss: 0.0004082845989614725\n",
      "Epoch [50/50], Step [700/938], Loss: 0.0005626102793030441\n",
      "Epoch [50/50], Step [800/938], Loss: 0.0009604498045518994\n",
      "Epoch [50/50], Step [900/938], Loss: 0.0031943924259394407\n",
      "Accuracy of the network on the 10000 test images: 97.74 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "# 2. 定义超参数\n",
    "input_size = 784  # MNIST图片大小是28x28\n",
    "hidden_sizes = [128, 64]  # 隐藏层的大小\n",
    "output_size = 10  # 输出的类别数为10，分别对应0到9的数字\n",
    "num_epochs = 50  # 进行5次训练迭代\n",
    "batch_size = 64  # 每批次处理64张图片\n",
    "learning_rate = 0.001  # 学习率设置为0.001\n",
    "\n",
    "# 3. 数据准备\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图片转换成PyTorch的Tensor格式\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 标准化处理，以减小模型对数据规模的敏感性\n",
    "])\n",
    "\n",
    "# 加载数据集，这里使用内置的MNIST数据集\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 4. 定义模型\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型并将其发送到设备\n",
    "model = NeuralNet(input_size, hidden_sizes, output_size).to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 5. 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 将图片和标签移动到设备\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item()}')\n",
    "\n",
    "# 测试模型，在测试阶段关闭梯度\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 准备一个示例输入，这将用于模型的跟踪\n",
    "example = torch.rand(1, input_size).to(device)\n",
    "\n",
    "# 使用 'torch.jit.trace' 方法追踪模型，或者使用 'torch.jit.script' 方法脚本化模型\n",
    "# 跟踪模型\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "\n",
    "# 保存追踪后的模型到磁盘\n",
    "traced_script_module.save(f\"minist_{num_epochs}.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T07:38:38.155150Z",
     "start_time": "2024-02-24T07:34:05.635874Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "577954e19674f9fc"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.066318\n",
      "Test set: Average loss: 0.0001, Accuracy: 9828/10000 (98%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.036448\n",
      "Test set: Average loss: 0.0000, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.024496\n",
      "Test set: Average loss: 0.0000, Accuracy: 9898/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.029727\n",
      "Test set: Average loss: 0.0000, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.007744\n",
      "Test set: Average loss: 0.0000, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.078606\n",
      "Test set: Average loss: 0.0000, Accuracy: 9918/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.025351\n",
      "Test set: Average loss: 0.0000, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.031085\n",
      "Test set: Average loss: 0.0000, Accuracy: 9932/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.003925\n",
      "Test set: Average loss: 0.0000, Accuracy: 9935/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.014702\n",
      "Test set: Average loss: 0.0000, Accuracy: 9943/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.008130\n",
      "Test set: Average loss: 0.0000, Accuracy: 9937/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.053454\n",
      "Test set: Average loss: 0.0000, Accuracy: 9945/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.016856\n",
      "Test set: Average loss: 0.0000, Accuracy: 9942/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.002015\n",
      "Test set: Average loss: 0.0000, Accuracy: 9933/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.014135\n",
      "Test set: Average loss: 0.0000, Accuracy: 9939/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.057024\n",
      "Test set: Average loss: 0.0000, Accuracy: 9945/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 0\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.000145\n",
      "Test set: Average loss: 0.0000, Accuracy: 9941/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.043451\n",
      "Test set: Average loss: 0.0000, Accuracy: 9940/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.003356\n",
      "Test set: Average loss: 0.0000, Accuracy: 9938/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.001284\n",
      "Test set: Average loss: 0.0000, Accuracy: 9947/10000 (99%)\n",
      "\n",
      "JIT compiled model saved at epoch 20\n",
      "Training complete! Best JIT compiled model saved with epoch 16 and loss 0.0000.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        # Dropout层\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 256) # 更正全连接层输入特征数\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.batchnorm3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'\\rTrain Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}',end='')\n",
    "\n",
    "# 测试模型\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.CrossEntropyLoss()(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * accuracy:.0f}%)\\n')\n",
    "    return test_loss, correct, accuracy  # 添加返回值\n",
    "\n",
    "# 定义 JIT 模型保存函数\n",
    "def save_jit_model(model, epoch, device, example, filename_prefix):\n",
    "    model.eval()\n",
    "    traced_script_module = torch.jit.trace(model, example)\n",
    "    traced_script_module.save(f\"{filename_prefix}_{epoch}.pt\")\n",
    "    print(f\"JIT compiled model saved at epoch {epoch}\")\n",
    "\n",
    "# 设置种子和设备\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transform),\n",
    "    batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transform),\n",
    "    batch_size=1000, shuffle=True)\n",
    "\n",
    "# 实例化模型和优化器\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "num_epochs = 200\n",
    "save_interval = 100\n",
    "best_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "# 准备示例输入\n",
    "example = torch.rand(1, 1, 28, 28).to(device)\n",
    "\n",
    "# 训练和测试\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test_loss, correct, accuracy = test(model, device, test_loader)\n",
    "\n",
    "    # 每隔save_interval个epoch保存一次JIT编译后的模型\n",
    "    if epoch % save_interval == 0 and epoch != num_epochs:\n",
    "        save_jit_model(model, epoch, device, example, \"minist_cnn_jit_checkpoint\")\n",
    "\n",
    "    # 保存表现最好的JIT编译后的模型\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        best_epoch = epoch\n",
    "        save_jit_model(model, 0, device ,example, \"best\")\n",
    "\n",
    "# 最后保存经过训练的JIT编译后的模型\n",
    "save_jit_model(model, num_epochs, device, example, \"minist_cnn_jit\")\n",
    "\n",
    "print(f\"Training complete! Best JIT compiled model saved with epoch {best_epoch} and loss {best_loss:.4f}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T13:20:22.680736Z",
     "start_time": "2024-02-28T13:17:11.015929Z"
    }
   },
   "id": "28c0b3f553894bae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "315326aed67d9ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
